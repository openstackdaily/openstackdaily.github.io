<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rate Limiting Like a Boss: Surviving the 10M Request Apocalypse | Tech Interview Blog</title>
  <meta name="description" content="Build a distributed rate limiting system that handles 10M requests/minute with Redis clusters, local caching, and token bucket algorithms. Learn from Stripe's approach.">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=JetBrains+Mono&family=Merriweather:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({startOnLoad:true,theme:'dark',themeVariables:{primaryColor:'var(--accent)',primaryTextColor:'var(--text)',primaryBorderColor:'var(--border)',lineColor:'var(--accent)',secondaryColor:'var(--bg-secondary)',tertiaryColor:'var(--bg-card)'}});</script>
  <link rel="stylesheet" href="/style.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>üöÄ</text></svg>">
</head>
<body>
<header><div class="container header-content">
    <a href="/" class="logo">üöÄ DevInsights</a>
    <nav>
      <a href="/">Home</a>
      <a href="/categories/">Topics</a>
      <a href="https://reel-interview.github.io" target="_blank">Practice ‚Üí</a>
    </nav>
  </div></header>
<main><article class="article"><div class="container">
  <a href="/categories/system-design/" style="color:var(--text-secondary);text-decoration:none;font-size:0.875rem">‚Üê System Design</a>
  <div class="article-header">
    <h1>Rate Limiting Like a Boss: Surviving the 10M Request Apocalypse</h1>
    <div class="article-meta"><span class="tag">System Design</span><span class="difficulty advanced">advanced</span><span class="tag">api</span> <span class="tag">rest</span></div>
  </div>
  <p class="article-intro">Ever had your API crash at 3am because a viral tweet sent 10M requests your way? We've all been there - watching our beautiful architecture crumble under unexpected load. Let's build a rate limiting system that laughs in the face of traffic spikes and keeps your services running smoothly.</p>
  <div class="article-content">
    <h2>The Problem: When Good APIs Go Bad</h2>Picture this: You're sleeping peacefully when your phone explodes with alerts. Your microservices are drowning in requests, databases are timing out, and users are tweeting about your "unreliable" service. Sound familiar?</p><p>üí° <strong>Pro Tip:</strong> Rate limiting isn't just about preventing abuse - it's about survival. A good rate limiter is like a bouncer at an exclusive club, keeping the riff-raff out while letting the VIPs through.</p><p><strong>The Numbers Game:</strong><br><ul><li>10M requests/minute = 167K requests/second</li><br><li>100+ microservices with different policies</li><br><li>Sub-5ms latency requirement</li><br><li>99.99% availability target</li></ul><h2>Architecture: The Three-Layer Cake</h2>Think of rate limiting like a wedding cake - each layer serves a purpose, and together they create something beautiful (and functional).</p><p><strong>Layer 1: Redis Cluster (The Foundation)</strong><br><ul><li>6 nodes with 3-way replication</li><br><li><span class="glossary-term" data-tooltip="Hashing method that minimizes key relocations when nodes are added or removed">Consistent hashing</span> for even distribution</li><br><li><span class="glossary-term" data-tooltip="Rate limiting algorithm that uses tokens refilled at a constant rate to control request bursts">Token bucket</span> algorithm implementation</li><br><li>Handles the heavy lifting of distributed state</li><br></ul><br><strong>Layer 2: Local Cache (The Middle Layer)</strong><br><ul><li><span class="glossary-term" data-tooltip="Cache eviction policy that removes least recently used items when capacity is reached">LRU cache</span> with 30s TTL per service</li><br><li>Acts as a safety net during Redis failures</li><br><li>Reduces Redis load by 80-90%</li><br><li>Sub-millisecond response times</li><br></ul><br><strong>Layer 3: SDK (The Icing)</strong><br><ul><li>Hierarchical enforcement (global ‚Üí service ‚Üí endpoint)</li><br><li>Circuit breakers for fault isolation</li><br><li>Automatic fallback mechanisms</li><br></ul><br>‚ö†Ô∏è <strong>Gotcha:</strong> Don't skip the local cache! I learned this the hard way when our Redis cluster went down during a peak traffic event. The local cache saved us from a complete outage.<h2>Token Bucket: The Magic Algorithm</h2>The <span class="glossary-term" data-tooltip="Rate limiting algorithm that uses tokens refilled at a constant rate to control request bursts">token bucket</span> algorithm is like giving each user a prepaid debit card with automatic refills. They can spend their tokens quickly (bursts) or slowly (steady rate), but they can't go into debt.</p><p><strong>Why <span class="glossary-term" data-tooltip="Rate limiting algorithm that uses tokens refilled at a constant rate to control request bursts">Token Bucket</span> Rocks:</strong><br><ul><li>Allows controlled bursts (unlike sliding window)</li><br><li>Memory efficient (O(1) per key)</li><br><li>Easy to understand and implement</li><br><li>Handles variable refill rates</li><br></ul><br>üî• <strong>Hot Take:</strong> Fixed window counters are for amateurs. Real engineers use token buckets for the flexibility and burst handling.</p><p><strong>Implementation Reality Check:</strong><br><pre><code class="language-javascript">// The core logic - simplified but production-ready<br>async function checkLimit(key, capacity, refillRate) {<br>  const now = Date.now();<br>  const bucket = await redis.hgetall(key);<br>  <br>  if (!bucket.id) {<br>    bucket = { tokens: capacity, lastRefill: now };<br>  }<br>  <br>  const elapsed = now - bucket.lastRefill;<br>  const tokensToAdd = Math.floor(elapsed * refillRate / 1000);<br>  bucket.tokens = Math.min(capacity, bucket.tokens + tokensToAdd);<br>  bucket.lastRefill = now;<br>  <br>  if (bucket.tokens >= 1) {<br>    bucket.tokens -= 1;<br>    await redis.hset(key, bucket);<br>    await redis.expire(key, 3600);<br>    return true;<br>  }<br>  return false;<br>}<br></code></pre></p><p><strong>Big O Analysis:</strong><br><ul><li>Time: O(1) per request (constant time)</li><br><li>Space: O(n) where n = number of unique keys</li><br><li>Perfect for high-throughput scenarios</li></ul><h2>Consistency: The Eventual Truth</h2>Here's the secret: rate limiting doesn't need perfect consistency. Being "eventually right" is totally fine - and much faster.</p><p><strong>Consistency Trade-offs:</strong></p><p><table><thead><tr><th>Approach</th><th>Latency</th><th>Accuracy</th><th>Complexity</th></tr></thead><tbody><tr><td>Strong Consistency</td><td>50-100ms</td><td>100%</td><td>High</td></tr><tr><td><span class="glossary-term" data-tooltip="Consistency model where data becomes consistent over time, allowing for higher availability">Eventual Consistency</span></td><td>1-5ms</td><td>99.9%</td><td>Medium</td></tr><tr><td>Local Only</td><td>0.1ms</td><td>95%</td><td>Low</td></tr></tbody></table><br>üéØ <strong>Key Insight:</strong> For rate limiting, being 99.9% accurate with 5ms latency is better than being 100% accurate with 100ms latency. Users won't notice the 0.1% discrepancy, but they'll definitely notice the slowdown.</p><p><strong>Background Sync Strategy:</strong><br><ul><li>Periodic reconciliation every 30 seconds</li><br><li>Last-write-wins conflict resolution</li><br><li>Timestamp-based ordering</li><br><li>Automatic drift correction</li></ul><h2>Failure Handling: When Things Go Wrong</h2>Murphy's Law applies to distributed systems: anything that can go wrong, will go wrong. Here's how to survive.</p><p><strong>Redis Failover (<30 seconds):</strong><br>1. Sentinel detects node failure<br>2. Promotes replica to master<br>3. Updates client connections<br>4. Local cache handles requests during failover<br>5. Automatic resync when Redis recovers</p><p><strong>Network Partitions:</strong><br><ul><li>Majority writes for consistency</li><br><li>Local-first strategy with async sync</li><br><li>Conflict resolution on reconciliation</li><br><li>Graceful degradation with relaxed limits</li><br></ul><br>‚ö†Ô∏è <strong>Gotcha:</strong> Always test your failover scenarios. We once had a Redis failover that took 5 minutes instead of 30 seconds because of misconfigured Sentinels. The local cache saved us, but it was a stressful debugging session.<h2>Monitoring: What to Watch</h2>You can't improve what you don't measure. Here are the metrics that matter:</p><p><strong>Critical KPIs:</strong><br><ul><li>Rate limit hit ratio (target: <5%)</li><br><li>Redis latency (p95 < 5ms)</li><br><li>Cache miss rate (target: <10%)</li><br><li><span class="glossary-term" data-tooltip="Pattern that prevents cascade failures by stopping requests to failing services">Circuit breaker</span> activations (<1%)</li><br><li>Error rate (target: <0.1%)</li><br></ul><br><strong>SLA Targets:</strong><br><ul><li><strong>Availability:</strong> 99.99% (52 minutes downtime/year)</li><br><li><strong>Latency:</strong> p95 < 5ms, p99 < 10ms</li><br><li><strong>Accuracy:</strong> 99.9% (within 0.1% error rate)</li><br></ul><br>üí° <strong>Pro Tip:</strong> Set up alerts for when your rate limit hit ratio exceeds 5%. This usually indicates either an attack or that your limits are too restrictive.<h2>Cost Optimization: The Bottom Line</h2>Great architecture doesn't mean much if you can't afford it. Here's the reality check:</p><p><strong>Redis Costs:</strong><br><ul><li>Memory-optimized instances (r6g.2xlarge)</li><br><li>$0.376/hour √ó 6 nodes √ó 3 replicas = $2,256/month</li><br><li>Includes monitoring, backups, and support</li><br></ul><br><strong>Local Cache:</strong><br><ul><li>10MB per service for hot keys</li><br><li>Minimal CPU overhead (<1%)</li><br><li>Essentially free</li><br></ul><br><strong>Total Cost:</strong> ~$2,300/month for 10M requests/minute capacity</p><p>üî• <strong>Hot Take:</strong> That's $0.003 per million requests. Cheaper than most coffee shops!
    <div class="real-world-example">
      <h3>üè¢ Real-World Example</h3>
      <div class="company">Stripe</div>
      <p class="scenario">Stripe handles rate limiting for millions of API calls across their payment platform. They use a hierarchical approach with Redis clusters and local caching, achieving 99.99% availability while preventing abuse.</p>
      <div class="lesson">üí° <strong>Key Lesson:</strong> Stripe's key insight was that different endpoints need different rate limits. Payment processing gets stricter limits than balance checks, and they adjust these dynamically based on system load.</div>
    </div><h2>üìä Visual Overview</h2><div class="mermaid">graph TB
    Client[Client Request] --> SDK[Rate Limiting SDK]
    SDK --> LocalCache[Local Cache LRU + 30s TTL]
    SDK --> RedisCluster[Redis Cluster<br/>6 nodes, 3-way replication]
    
    RedisCluster --> Node1[Node 1]
    RedisCluster --> Node2[Node 2]
    RedisCluster --> Node3[Node 3]
    RedisCluster --> Node4[Node 4]
    RedisCluster --> Node5[Node 5]
    RedisCluster --> Node6[Node 6]
    
    Node1 --> Replica1[Replica 1]
    Node2 --> Replica2[Replica 2]
    Node3 --> Replica3[Replica 3]
    
    SDK --> CircuitBreaker[Circuit Breaker]
    CircuitBreaker --> Service[Microservice]
    
    LocalCache -.->|Fallback| Service
    
    subgraph "Hierarchical Limits"
        Global[Global: 10M req/min]
        ServiceLevel[Service: 100K req/min]
        Endpoint[Endpoint: 1K req/min]
    end
    
    SDK --> Global
    Global --> ServiceLevel
    ServiceLevel --> Endpoint</div><div class="fun-fact"><span class="fun-fact-icon">ü§ì</span><p><strong>Fun Fact:</strong> The token bucket algorithm was invented in the 1980s for telecommunication networks to control data flow in ATM switches. It's older than many developers reading this!</p></div><div class="quick-ref"><h3>üìå TL;DR - Quick Reference</h3><ul><li>Use Redis Cluster + local cache for 99.99% availability</li><li>Token bucket algorithm allows controlled bursts</li><li>Eventual consistency is fine for rate limiting</li><li>Always test failover scenarios before production</li></ul></div><div class="sources"><h3>üìñ Sources & Further Reading</h3><ul><li data-type="documentation"><a href="https://redis.io/docs/operate/oss_and_stack/management/cluster-tutorial/" target="_blank" rel="noopener">Redis Cluster Best Practices</a><span class="source-type">documentation</span></li><li data-type="blog"><a href="https://stripe.com/blog/rate-limiters" target="_blank" rel="noopener">Stripe API Rate Limiting</a><span class="source-type">blog</span></li><li data-type="blog"><a href="https://www.figma.com/blog/engineering/rate-limiting-at-scale/" target="_blank" rel="noopener">Rate Limiting Algorithms Comparison</a><span class="source-type">blog</span></li><li data-type="documentation"><a href="https://en.wikipedia.org/wiki/Token_bucket" target="_blank" rel="noopener">Token Bucket Algorithm Analysis</a><span class="source-type">documentation</span></li></ul></div>
    <h2>üé¨ Wrapping Up</h2>
    <p>Ready to build your bulletproof rate limiter? Start with a Redis cluster, add local caching, and implement the token bucket algorithm. Test your failover scenarios, monitor your key metrics, and you'll sleep better at night knowing your APIs can handle whatever the internet throws at them. Your future self (and your on-call team) will thank you.</p>
  </div>
  <div class="cta-box">
    <p>Ready to put this into practice?</p>
    <a href="https://reel-interview.github.io/channel/system-design" class="cta-button">Practice Interview Questions ‚Üí</a>
  </div>
</div></article></main>
<footer><div class="container">
    <div class="footer-content">
      <div class="footer-brand">üöÄ DevInsights</div>
      <div class="footer-links">
        <a href="/">Home</a>
        <a href="/categories/">Topics</a>
        <a href="https://reel-interview.github.io" target="_blank">Practice</a>
      </div>
    </div>
    <div class="footer-copy">
      <p>Built for devs who want to level up üî•</p>
      <p style="margin-top:0.5rem">¬© 2025 DevInsights ‚Ä¢ <a href="https://reel-interview.github.io">Reel Interview</a></p>
    </div>
  </div></footer></body></html>